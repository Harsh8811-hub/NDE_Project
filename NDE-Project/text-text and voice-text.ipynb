{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPRguhW4-4RO"
      },
      "outputs": [],
      "source": [
        "!pip install whisper python-docx Document gradio faiss-cpu PyPDF2 pikepdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfu0gQfq9g_k"
      },
      "outputs": [],
      "source": [
        "# 1. Install Dependencies\n",
        "!pip install -q sentence-transformers faiss-cpu google-generativeai PyMuPDF\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import fitz  # PyMuPDF\n",
        "import faiss\n",
        "import logging\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google import genai\n",
        "from textwrap import wrap\n",
        "\n",
        "# 2. Configure Gemini API\n",
        "GEMINI_API_KEY = \"\"\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# 3. Unzip Dataset\n",
        "zip_path = \"/content/dataset_NDE.zip\"\n",
        "extract_path = \"/content/nde_data\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# 4. Extract text from all PDFs\n",
        "def extract_text_from_pdfs(folder):\n",
        "    all_text = \"\"\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pdf\"):\n",
        "                path = os.path.join(root, file)\n",
        "                try:\n",
        "                    doc = fitz.open(path)\n",
        "                    for page in doc:\n",
        "                        all_text += page.get_text()\n",
        "                    doc.close()\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"Failed to extract {file}: {e}\")\n",
        "    return all_text\n",
        "\n",
        "raw_text = extract_text_from_pdfs(extract_path)\n",
        "if not raw_text.strip():\n",
        "    raise ValueError(\"No text found in PDF files. Check dataset.\")\n",
        "\n",
        "# 5. Create Chunks & Embed\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "chunks = wrap(raw_text, width=300)\n",
        "if not chunks:\n",
        "    raise ValueError(\"No chunks generated from extracted PDF text.\")\n",
        "embeddings = embed_model.encode(chunks, convert_to_numpy=True)\n",
        "\n",
        "# 6. Build FAISS Index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# 7. Chat Memory & Retrieval\n",
        "chat_history = []\n",
        "\n",
        "def retrieve_context(query, top_k=3):\n",
        "    query_embedding = embed_model.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(query_embedding, top_k)\n",
        "    return [chunks[i] for i in I[0]]\n",
        "\n",
        "def ask_nde_bot(user_input):\n",
        "    context_chunks = retrieve_context(user_input)\n",
        "    context_text = \"\\n\".join(context_chunks)\n",
        "    prompt = f\"\"\"\n",
        "You are an expert NDE (Non-Destructive Evaluation) assistant chatbot. Be accurate, correct wrong statements, and recall previous conversation if asked.\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "    response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
        "    answer = response.text.strip()\n",
        "    chat_history.append((user_input, answer))\n",
        "    print(\"Bot:\", answer)\n",
        "    return answer\n",
        "\n",
        "def recall_last_question():\n",
        "    if chat_history:\n",
        "        print(\"Last Question:\", chat_history[-1][0])\n",
        "        print(\"Bot's Answer:\", chat_history[-1][1])\n",
        "    else:\n",
        "        print(\"No previous questions found.\")\n",
        "\n",
        "# 8. Start Chatting!\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "    elif \"recall\" in user_input.lower() or \"previous question\" in user_input.lower():\n",
        "        recall_last_question()\n",
        "    else:\n",
        "        ask_nde_bot(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wx0G2zB9rad"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Voice Input‚ÄìEnabled NDE Chatbot Using Whisper + Gemini\n",
        "\n",
        "!pip install -q gradio openai-whisper google-generativeai\n",
        "\n",
        "import whisper\n",
        "import gradio as gr\n",
        "from google import genai\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "#  Set up Gemini client\n",
        "GEMINI_API_KEY = \"AIzaSyBtSFU9U0d5rO2wELWMA3P9pu_iEj34MGg\"\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "#  Load Whisper model (base is fast + accurate)\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "#  Function: Transcribe + Ask Gemini + Return Answer\n",
        "def full_pipeline(audio_path):\n",
        "    try:\n",
        "        # Transcribe with Whisper\n",
        "        result = model.transcribe(audio_path)\n",
        "        user_text = result[\"text\"]\n",
        "\n",
        "        # Ask Gemini\n",
        "        prompt = f\"You are an expert NDE (Non-Destructive Evaluation) assistant. Answer professionally: {user_text}\"\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=prompt\n",
        "        )\n",
        "        return f\"You said: {user_text}\\n\\nBot: {response.text.strip()}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "#  Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=full_pipeline,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"üéôÔ∏è Speak your NDE question\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"üîç NDE Voice Assistant\",\n",
        "    description=\"Ask your NDE-related questions by voice.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
